{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import enchant\n",
    "import csv\n",
    "import re\n",
    "import time\n",
    "from nltk.translate.bleu_score import sentence_bleu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Funciones auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jsonToDict(route) -> dict:\n",
    "    '''\n",
    "    Funcion auxiliar que dada la ruta de un json, lo abre y lo convierte a diccionario\n",
    "    '''\n",
    "    with open(route, encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def queryJSON(queryURL, json):\n",
    "    '''\n",
    "    Funcion auxiliar que dado un JSON con una pregunta, realiza una consulta (con esta pregunta) a una URL\n",
    "    '''\n",
    "    question = json['question']\n",
    "    files = {\n",
    "        'question': (None, question),\n",
    "    }\n",
    "    '''\n",
    "    En caso de que quisiesemos la respuesta verbalizada o larga, hacer la request con params = payload:\n",
    "    payload = {\n",
    "        ('text', 'true')\n",
    "    }\n",
    "    '''\n",
    "    response = requests.get(queryURL, files = files)\n",
    "    #Obtenemos la respuesta como JSonObject y la devolvemos\n",
    "    return response.json()\n",
    "\n",
    "def writeResults(csvwriter, question, modelAnswerLong, obtainedAnswer, queryTime, textLen):  \n",
    "    '''\n",
    "    Funcion auxiliar que extrae la respuesta que se espera, hace la distancia de levenshtein y escribe en el csv:\n",
    "    -Pregunta\n",
    "    -Respuesta modelo y nuestra respuesta\n",
    "    -Distancia de levenshtein entre ambas respuestas\n",
    "    -Tiempo que ha tardado en ejecutarse la consulta\n",
    "    -Longitud del texto del que se ha obtenido nuestra respuesta\n",
    "    -Si la pregunta dada tiene respuesta modelo o no\n",
    "    '''    \n",
    "    #La respuesta esperada se obtiene con una expresion regular (sacar texto entre corchetes)\n",
    "    modelAnswerLongGroups = re.search(r\"\\[([^\\)]+)\\]\", modelAnswerLong)\n",
    "    if(modelAnswerLongGroups is not None):\n",
    "        modelAnswer = modelAnswerLongGroups.group(1)\n",
    "        isAnswered = \"YES\"\n",
    "        if modelAnswer == \"answer\":\n",
    "            isAnswered = \"NO\" \n",
    "        distance = \"None\"\n",
    "        if obtainedAnswer is not None:\n",
    "            distance = enchant.utils.levenshtein(modelAnswer,obtainedAnswer)\n",
    "            reference = [modelAnswer.split()]\n",
    "            candidate = obtainedAnswer.split()\n",
    "            bleu = sentence_bleu(reference, candidate)\n",
    "\n",
    "        csvwriter.writerow( [question, modelAnswer, obtainedAnswer, distance , queryTime, textLen, isAnswered] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Funcion principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareAnswersJSON(JSONroute, queryURL, csvRoute):\n",
    "    '''\n",
    "    Función que dado un JSON con preguntas y respuestas (asumimos que las preguntas están en la clave 'question' del JSON, y las respuestas en 'verbalized_answers'), \n",
    "    una url a través de la cual realizar consultas y un csv donde guardar los resultados:\n",
    "    - Realiza las preguntas del JSON dado\n",
    "    - Lo compara con la respuesta esperada segun la Distancia de Levenshtein\n",
    "    - Guarda en el CSV la pregunta, la respuesta esperada, la respuesta obtenida y varias metricas de rendimiento\n",
    "    '''\n",
    "    VQuandaData = jsonToDict(JSONroute)\n",
    "\n",
    "    with open(csvRoute,'w', newline='', encoding=\"utf-8\") as f:\n",
    "\n",
    "        csvwriter = csv.writer(f,delimiter=';', quotechar='\"', quoting=csv.QUOTE_ALL)\n",
    "\n",
    "        #Escribimos el Header\n",
    "        csvwriter.writerow( [\"Question\", \"Answer\", \"Response\", \"Levenshtein Distance\",\"BLEU Score\",\"Query Time\",\"Text Length\",\"Is Answered\"])\n",
    "        counter = 0\n",
    "        \n",
    "        for i in VQuandaData:\n",
    "\n",
    "            #Para medir el tiempo que se tarda en ejecutar la consulta\n",
    "            queryStartTime = time.time()\n",
    "            jsonResponse = queryJSON(queryURL,i)\n",
    "            queryTime = round((time.time() - queryStartTime),2)\n",
    "\n",
    "            #Pasamos las respuestas a minuscula y llamamos a extractAndCompare.\n",
    "            writeResults(csvwriter, i['question'], i['verbalized_answer'].lower(),jsonResponse['answer'].lower(),queryTime,jsonResponse['textLen'])\n",
    "            counter += 1\n",
    "            if(counter % 50 == 0):\n",
    "                print(\"Reached question \" + str(counter))\n",
    "\n",
    "        f.close()\n",
    "        print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Ejecucion script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compareAnswersJSON(\"train.JSON\",\"https://librairy.linkeddata.es/eqakg/dbpedia/en?text=false\",\"levenshtein.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
